{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b7e550",
   "metadata": {},
   "source": [
    "# Sesión 11 A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1b7a14",
   "metadata": {},
   "source": [
    "> **Objetivos:**\n",
    "> - Entender los diferentes tipos de consultas que le podemos hacer a un modelo gráfico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d8a218",
   "metadata": {},
   "source": [
    "### 1. Introducción\n",
    "\n",
    "En la sesión pasada comenzamos a estudiar el tema de _redes bayesianas_ y vimos que:\n",
    "\n",
    "En una red bayesiana, los _tipos de razonamiento_ describen cómo fluye la información a través del grafo:\n",
    "\n",
    "| Tipo de razonamiento | Dirección | Ejemplo | Intuición |\n",
    "|----------------------|------------|----------|-----------|\n",
    "| **Causal (predictivo)** | Causa → Efecto | $P(\\text{Fiebre} \\mid \\text{Gripe})$ | Predecir consecuencias de causas. |\n",
    "| **Evidencial (diagnóstico)** | Efecto → Causa | $P(\\text{Gripe} \\mid \\text{Fiebre})$ | Diagnosticar causas a partir de efectos. |\n",
    "| **Intercausal** | Entre causas de un mismo efecto | $P(\\text{Aspersores} \\mid \\text{Césped mojado}, \\text{Lluvia})$ | Explicar relaciones entre causas que comparten un efecto. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95ec44a",
   "metadata": {},
   "source": [
    "En esta sesión veremos los **tipos de consultas**. Éstos nos dicen _cómo queremos responder_ una pregunta probabilística usando un modelo gráfico.\n",
    "\n",
    "| Tipo de consulta | Qué calcula | Respuesta |\n",
    "|------------------|--------------|-----------|\n",
    "| **Probabilística (posterior query)** | $P(Y \\mid \\text{Evidencia})$ | Distribución completa sobre $Y$ |\n",
    "| **MAP (decisión puntual)** | $\\arg\\max_Y P(Y \\mid \\text{Evidencia})$ | El valor más probable de $Y$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38494310",
   "metadata": {},
   "source": [
    "#### 1.1. Consultas probabilísticas\n",
    "\n",
    "Las **consultas probabilísticas** son el tipo de consulta más común en los modelos gráficos probabilísticos.  \n",
    "\n",
    "Básicamente, nos permiten responder preguntas del tipo:\n",
    "\n",
    "> \"¿Cuál es la probabilidad de que ocurra algo _(una variable de interés)_?\"\n",
    "\n",
    "> \"¿Cuál es la probabilidad de que ocurra algo _(una variable de interés)_, sabiendo que ya observamos otra cosa _(una evidencia)_?\"\n",
    "\n",
    "Por ejemplo:  \n",
    "> “¿Cuál es la probabilidad de que un estudiante apruebe?”  \n",
    "> “¿Cuál es la probabilidad de que llueva, dado que el cielo está nublado?”\n",
    "\n",
    "---\n",
    "\n",
    "Sea el conjunto completo de variables aleatorias del modelo:\n",
    "\n",
    "$$\n",
    "P(X_1, \\ldots, X_n)\n",
    "$$\n",
    "\n",
    "(modelada a través de una red Bayesiana).\n",
    "\n",
    "Definimos:\n",
    "\n",
    "* Un conjunto de **variables de interés**:\n",
    "\n",
    "  $$\n",
    "  \\bar{Y} \\subseteq \\{X_1, \\dots, X_n\\}\n",
    "  $$\n",
    "\n",
    "> Son las variables sobre las que queremos conocer.\n",
    "\n",
    "* Un conjunto de **variables de evidencia (observadas)**:\n",
    "\n",
    "  $$\n",
    "  \\bar{E} = \\bar{e}, \\quad \\text{con } \\bar{E} \\subseteq \\{X_1, \\dots, X_n\\}\n",
    "  $$\n",
    "\n",
    "> Son las variables cuyo valor ya conocemos (por ejemplo, síntomas observados, resultados medidos, etc.).\n",
    "\n",
    "* El conjunto restante de variables no observadas ni consultadas:\n",
    "  $$\n",
    "  \\bar{W} = \\{X_1, \\dots, X_n\\} \\setminus (\\bar{Y} \\cup \\bar{E})\n",
    "  $$\n",
    "\n",
    "> Son las variables “ocultas” o que no intervienen directamente en la consulta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce56dde",
   "metadata": {},
   "source": [
    "El objetivo de la inferencia es **calcular la probabilidad condicional** de las variables de interés dado el conjunto de evidencias observadas:\n",
    "\n",
    "$$\n",
    "P(\\bar{Y} \\mid \\bar{E} = \\bar{e})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc1f912",
   "metadata": {},
   "source": [
    "**¿Cómo?**\n",
    "\n",
    "Por la definición de probabilidad condicional:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "P(\\bar{Y} \\mid \\bar{E} = \\bar{e}) = \\frac{P(\\bar{Y}, \\bar{e})}{P(\\bar{e})}\n",
    "}\n",
    "$$\n",
    "\n",
    "En esta expresión:\n",
    "\n",
    "- $P(\\bar{Y}, \\bar{e}) = \\sum_{\\bar{W}} P(\\bar{Y}, \\bar{e}, \\bar{W})$  \n",
    "\n",
    "  Recordemos que $\\{X_1, \\dots, X_n\\} = \\bar{Y} \\cup \\bar{E} \\cup \\bar{W}$.  \n",
    "  Por lo tanto, los términos dentro de la suma representan las **probabilidades conjuntas** de todas las variables del modelo.\n",
    "\n",
    "- $P(\\bar{e}) = \\sum_{\\bar{Y}} P(\\bar{Y}, \\bar{e})$  \n",
    "\n",
    "  Esta cantidad actúa como una **constante de normalización**, necesaria para convertir la distribución conjunta $P(\\bar{Y}, \\bar{e})$ en una distribución condicional válida $P(\\bar{Y} \\mid \\bar{e})$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882d12f3",
   "metadata": {},
   "source": [
    "> Lo anterior es, en esencia, lo que ya habíamos estado realizando con el ejemplo del **modelo del estudiante**.\n",
    ">\n",
    "> Recordemos que aplicábamos la **fórmula de la probabilidad condicional** y luego **marginalizábamos** sobre las variables no observadas para obtener las distribuciones condicionales de interés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49fb9477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianNetwork, DiscreteBayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "import os\n",
    "from functools import reduce\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45c1ce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pgmpy.models.DiscreteBayesianNetwork.DiscreteBayesianNetwork'>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "ruta_modelo = os.path.join('..', 'data', 'student-model.pkl')\n",
    "with open(ruta_modelo, 'rb') as f:\n",
    "    student_model = pickle.load(f)\n",
    "\n",
    "print(type(student_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c171ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "factores = [cpd.to_factor() for cpd in student_model.get_cpds()]\n",
    "p_joint = reduce(lambda x, y: x * y, factores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d528d5fa",
   "metadata": {},
   "source": [
    "Retomando una de las consultas que hicimos la sesión pasada:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e88829",
   "metadata": {},
   "source": [
    "> ¿Cuál es la probabilidad de que un estudiante obtenga una carta de recomendación (R), dado que no estudió mucho (I=0)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93809bfa",
   "metadata": {},
   "source": [
    "$$P(r^1 | i^0) = \\frac{P(r^1, i^0)}{P(i^0)} = \\frac{\\sum_{D,C,E} P(D, i^0, C, E, r^1)}{\\sum_{D,C,E,R} P(D, i^0, C, E, R)} \\approx ?$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f3d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_RI = p_joint.marginalize(variables=['D', 'C', 'E'], inplace=False)\n",
    "p_I = p_joint.marginalize(variables=['D', 'C', 'E', 'R'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa42f90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------------+\n",
      "| R    | I    |   phi(R,I) |\n",
      "+======+======+============+\n",
      "| R(0) | I(0) |     0.4280 |\n",
      "+------+------+------------+\n",
      "| R(0) | I(1) |     0.0697 |\n",
      "+------+------+------------+\n",
      "| R(1) | I(0) |     0.2720 |\n",
      "+------+------+------------+\n",
      "| R(1) | I(1) |     0.2303 |\n",
      "+------+------+------------+\n"
     ]
    }
   ],
   "source": [
    "# numerador\n",
    "print(p_RI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4faa613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "| I    |   phi(I) |\n",
      "+======+==========+\n",
      "| I(0) |   0.7000 |\n",
      "+------+----------+\n",
      "| I(1) |   0.3000 |\n",
      "+------+----------+\n"
     ]
    }
   ],
   "source": [
    "# denominador\n",
    "print(p_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76df60c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "| R    |   phi(R) |\n",
      "+======+==========+\n",
      "| R(0) |   0.4280 |\n",
      "+------+----------+\n",
      "| R(1) |   0.2720 |\n",
      "+------+----------+\n"
     ]
    }
   ],
   "source": [
    "p_RI0 = p_RI.reduce([('I', 0)], inplace=False) # nos quedamos con I=0 (evidencia)\n",
    "print(p_RI0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "611305dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi0 = p_I.get_value(I=0) # normalizador (evidencia)\n",
    "pi0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6b575f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R(0) = 0.6113999999999999\n",
      "R(1) = 0.38860000000000006\n"
     ]
    }
   ],
   "source": [
    "print('R(0) =', p_RI0.values[0]/pi0)\n",
    "print('R(1) =', p_RI0.values[1]/pi0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1baa68d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6114 0.3886]\n"
     ]
    }
   ],
   "source": [
    "p_R_given_I0_vals = p_RI0.values / pi0  # vector \n",
    "print(p_R_given_I0_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb08a99a",
   "metadata": {},
   "source": [
    "La consulta actual:\n",
    "\n",
    "$$\n",
    "P(r^1 \\mid i^0) = \\frac{P(r^1, i^0)}{P(i^0)}\n",
    "$$\n",
    "\n",
    "produce una **distribución condicional** sobre $R$, dado que $I = i^0$.  \n",
    "\n",
    "Obtuvimos:\n",
    "\n",
    "$$\n",
    "P(R \\mid I = i^0) = [0.6114,\\; 0.3886]\n",
    "$$\n",
    "\n",
    "que representa:\n",
    "\n",
    "$$\n",
    "P(R = r^0 \\mid I = i^0) = 0.6114 \\quad \\text{y} \\quad P(R = r^1 \\mid I = i^0) = 0.3886\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca00d540",
   "metadata": {},
   "source": [
    "### 1.2. Inferencia Máximo a Posteriori (MAP)\n",
    "\n",
    "En la sección anterior vimos que la inferencia mediante **probabilidad condicional** nos entrega una **distribución completa** sobre las posibles combinaciones de las variables de interés, dadas las evidencias observadas.\n",
    "\n",
    "Por ejemplo, al calcular:\n",
    "\n",
    "$$\n",
    "P(\\bar{Y} \\mid \\bar{E} = \\bar{e})\n",
    "$$\n",
    "\n",
    "obtenemos **todas** las probabilidades posibles de $\\bar{Y}$ (una tabla que suma 1).  \n",
    "\n",
    "Sin embargo, a veces **no necesitamos toda la distribución**, sino **el valor más probable**: la combinación de estados de las variables de interés que **maximiza** esa probabilidad condicional.\n",
    "\n",
    "A esto lo llamamos **Inferencia máximo a posteriori (MAP)**:\n",
    "\n",
    "$$\n",
    "MAP(\\bar{Y} \\mid \\bar{E} = \\bar{e}) = \n",
    "\\arg\\max_{\\bar{y}} P(\\bar{Y} = \\bar{y} \\mid \\bar{E} = \\bar{e})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747ead1f",
   "metadata": {},
   "source": [
    "El método ``map_query`` nos ayuda a realizar este tipo de consultas en una red bayesiana."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3a3a17",
   "metadata": {},
   "source": [
    "$$P(R \\mid i^0)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "062246d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22073ddc81554be89f430a379626cb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6512a649db439fba760ecb2fd5aac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R': 0}\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "infer = VariableElimination(student_model)\n",
    "r_map = infer.map_query(variables=[\"R\"], #variables = var de interés;\n",
    "                        evidence={\"I\": 0})  # evidence = evidencia\n",
    "print(r_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576f9de7",
   "metadata": {},
   "source": [
    "Este `R:0` nos indica el valor más probable de la variable `R`, dado que `I=0`.\n",
    "\n",
    "> Traducido: **el valor más probable de `R` es `0` (no obtiene carta de recomendación) cuando `I=0` (estudiante no muy destacado).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f362db50",
   "metadata": {},
   "source": [
    "El **máximo a posteriori (MAP)** no siempre coincide con el **máximo sobre las distribuciones marginales**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0871ef4d",
   "metadata": {},
   "source": [
    "![](../images/sesion11-map2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d28436",
   "metadata": {},
   "source": [
    "**Figura 1:** Diferencia entre el valor MAP y el valor máximo de las distribuciones marginales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75305fd",
   "metadata": {},
   "source": [
    "> En la **Figura 1**, el par más probable conjuntamente es $(A=a^0, B=b^1)$ con $P=0.36$ (MAP conjunto).\n",
    ">\n",
    "> Pero si tomamos los valores más probables de cada variable por separado —$A=a^1$ y $B=b^1$ según sus marginales— obtenemos $(a^1, b^1)$, cuya probabilidad conjunta es menor ($0.30$).\n",
    ">\n",
    ">maximizar las marginales busca los valores más probables individualmente, mientras que el MAP busca la combinación más probable en conjunto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1c28a3",
   "metadata": {},
   "source": [
    "### 1.3. Escalando a redes bayesianas grandes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de7f946",
   "metadata": {},
   "source": [
    "![](../images/sesion9-student-model-factors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4e175",
   "metadata": {},
   "source": [
    "**Figura 2:** Factorización del modelo del estudiante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7270dcb8",
   "metadata": {},
   "source": [
    "> Como se mencionó anteriormente, el modelo del estudiante es un ejemplo de *“juguete”*, es decir, un caso simplificado con pocas variables y cardinalidades reducidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6929441a",
   "metadata": {},
   "source": [
    "En modelos reales, las redes bayesianas pueden tener **decenas o cientos de variables** conectadas (como la de la **Figura 3**).\n",
    "\n",
    "Cada nodo representa una variable aleatoria y las conexiones codifican relaciones de dependencia probabilística.  \n",
    "\n",
    "El cálculo de una probabilidad como:\n",
    "\n",
    "$$\n",
    "P(X \\mid \\text{evidencia})\n",
    "$$\n",
    "\n",
    "implica **sumar o marginalizar** sobre *todas* las demás variables no observadas del modelo:\n",
    "\n",
    "$$\n",
    "P(X \\mid E=e) = \\frac{\\sum_Y P(X, Y, E=e)}{P(E=e)}\n",
    "$$\n",
    "\n",
    "A medida que crece el número de nodos, esta suma se vuelve **exponencialmente costosa**, porque el número de combinaciones posibles de estados explota.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06360953",
   "metadata": {},
   "source": [
    "Veamos lo siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b9cbce",
   "metadata": {},
   "source": [
    "![Ejemplo](../images/sesion11-ejem.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c0a662",
   "metadata": {},
   "source": [
    "**Figura 3. Modelo diagnóstico de endometriosis**\n",
    "\n",
    "Piensa en el crecimiento de una red bayesiana:\n",
    "\n",
    "- Cada variable puede tener varios **estados** (por ejemplo, *sí/no* o *bajo/medio/alto*).\n",
    "- Cada nodo depende de sus **padres** y sus tablas de probabilidad condicional crecen **exponencialmente** con el número de padres.\n",
    "- Para calcular una probabilidad marginal o condicional, hay que **sumar o multiplicar sobre todas las combinaciones posibles** de los valores de las variables no observadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60352029",
   "metadata": {},
   "source": [
    "![](../images/sesion11-endom-full.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6d8f03",
   "metadata": {},
   "source": [
    "**Figura 4. Modelo diagnóstico de endometriosis completo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e4748",
   "metadata": {},
   "source": [
    "Cuando la red contiene muchas variables (como en el ejemplo de la red diagnóstica de endometriosis u otras más densas), el número de combinaciones posibles se vuelve **gigante** y el tiempo de cómputo crece **más rápido que cualquier función polinomial** del número de nodos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cad39ab",
   "metadata": {},
   "source": [
    "> Por este motivo, en esta sesión exploraremos **métodos prácticos de inferencia en redes bayesianas**, que permiten realizar los mismos cálculos de forma más eficiente y escalable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eef928",
   "metadata": {},
   "source": [
    "![](../images/locomotive.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aca5de7",
   "metadata": {},
   "source": [
    "**Figura 5.** Red bayesiana que modela diversos problemas encontrados en el diagnóstico de locomotoras diésel, sus posibles causas, síntomas y resultados de las pruebas. Retomada de: [BayesFusion](https://www.bayesfusion.com/bayesian-networks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c22ab11",
   "metadata": {},
   "source": [
    "```{admonition} Ejemplo de red bayesiana grande\n",
    ":class: tip\n",
    "\n",
    "En la **Figura 5** se muestra un ejemplo de una red bayesiana que modela *2,127 variables binarias*.\n",
    "\n",
    "Si quisiéramos representar la distribución conjunta completa **sin aprovechar ninguna independencia condicional**, sería necesario almacenar\n",
    "\n",
    "$$\n",
    "2^{2127} \\approx 10^{640}\n",
    "$$\n",
    "\n",
    "entradas en una tabla de probabilidad conjunta, una cantidad completamente inabordable.\n",
    "\n",
    "Gracias a la estructura de dependencias codificada por la red bayesiana, esta distribución puede representarse con\n",
    "\n",
    "$$6,433 \\text{ parámetros independientes}$$\n",
    "\n",
    "Sin embargo, *reducir la cantidad de parámetros* no implica que la inferencia sea sencilla.\n",
    "\n",
    "Calcular probabilidades **marginales** o **condicionales** aún puede requerir recorrer una cantidad exponencial de combinaciones posibles de valores, lo que vuelve el proceso computacionalmente intractable en redes grandes.\n",
    "\n",
    "Esta limitación da lugar a dos enfoques principales para la inferencia en redes bayesianas...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed0b09a",
   "metadata": {},
   "source": [
    "#### 1.4. Inferencia exacta vs. inferencia aproximada\n",
    "\n",
    "Existen dos enfoques principales para hacer inferencia en redes grandes:\n",
    "\n",
    "1. **Inferencia exacta:**  \n",
    "   Calcula el valor exacto de las probabilidades, pero puede ser muy costosa computacionalmente.  \n",
    "   - El algoritmo más común es la **Eliminación de Variables** (*Variable Elimination*).\n",
    "\n",
    "2. **Inferencia aproximada:**  \n",
    "   - Utiliza muestreo o métodos numéricos para **estimar** las probabilidades cuando la exacta es inviable.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fccc06",
   "metadata": {},
   "source": [
    "[1] R. Collins and N. Fenton, \"Bayesian network modelling for early diagnosis and prediction of Endometriosis,\" *medRxiv*, preprint, Nov. 2020. Disponible: https://www.medrxiv.org/content/10.1101/2020.11.04.20225946v1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
